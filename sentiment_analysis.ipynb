{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e64eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8812c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f84d2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d476d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment_detail(text) :\n",
    "    # 문장을 토큰화하고 텐서로 변환\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # 모델을 사용하여 예측 수행\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 예측 결과 해석\n",
    "    logits = outputs.logits\n",
    "    probabilities = F.softmax(logits, dim=1)  # 각 레이블에 대한 확률 계산\n",
    "    predicted_class_id = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "    # 레이블 ID와 레이블 이름을 매핑\n",
    "    label_map = model.config.id2label\n",
    "    predicted_label = label_map[predicted_class_id]\n",
    "    predicted_score = probabilities[0][predicted_class_id].item()\n",
    "\n",
    "    # 모든 레이블에 대한 점수 출력\n",
    "    all_scores = {label_map[i]: probabilities[0][i].item() for i in range(len(label_map))}\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Sentiment: {predicted_label} (Score: {predicted_score:.4f})\")\n",
    "    print(\"All Scores:\", all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2bfa2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text) :\n",
    "    # 문장을 토큰화하고 텐서로 변환\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # 모델을 사용하여 예측 수행\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 예측 결과 해석\n",
    "    logits = outputs.logits\n",
    "    probabilities = F.softmax(logits, dim=1)  # 각 레이블에 대한 확률 계산\n",
    "    predicted_class_id = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "    # 레이블 ID와 레이블 이름을 매핑\n",
    "    label_map = model.config.id2label\n",
    "    predicted_label = label_map[predicted_class_id]\n",
    "    #predicted_score = probabilities[0][predicted_class_id].item()\n",
    "    predicted_score = probabilities[0][1].item()\n",
    "\n",
    "    # 모든 레이블에 대한 점수 출력\n",
    "    #all_scores = {label_map[i]: probabilities[0][i].item() for i in range(len(label_map))}\n",
    "    \n",
    "    #print(f\"Text: {text}\")\n",
    "    #print(f\"Predicted Sentiment: {predicted_label} (Score: {predicted_score:.4f})\")\n",
    "    #print(\"All Scores:\", all_scores)\n",
    "    \n",
    "    return predicted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ce6c3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(text) :\n",
    "    # 문장을 토큰화하고 텐서로 변환\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # 모델을 사용하여 예측 수행\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 예측 결과 해석\n",
    "    logits = outputs.logits\n",
    "    probabilities = F.softmax(logits, dim=1)  # 각 레이블에 대한 확률 계산\n",
    "    predicted_class_id = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "    # 레이블 ID와 레이블 이름을 매핑\n",
    "    label_map = model.config.id2label\n",
    "    predicted_label = label_map[predicted_class_id]\n",
    "    #predicted_score = probabilities[0][predicted_class_id].item()\n",
    "\n",
    "    # 모든 레이블에 대한 점수 출력\n",
    "    #all_scores = {label_map[i]: probabilities[0][i].item() for i in range(len(label_map))}\n",
    "    \n",
    "    #print(f\"Text: {text}\")\n",
    "    #print(f\"Predicted Sentiment: {predicted_label} (Score: {predicted_score:.4f})\")\n",
    "    #print(\"All Scores:\", all_scores)\n",
    "    \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a48d6ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '안녕하세요. 또 만났군요.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4fa5dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d4c41906",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f5ee595b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0338, -0.0028]], device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a899f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e1ac01db",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = F.softmax(logits, dim=1)  # 각 레이블에 대한 확률 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4d668c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4923, 0.5077]], device='cuda:0')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d8507fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(probabilities, dim=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d4324be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available device:  cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('available device: ', device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('available device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5ab599f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0', 1: '1'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5480927",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/home/osung/models/huggingface/sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3ebeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at /home/osung/models/huggingface/sentiment and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('/home/osung/models/huggingface/sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fd0e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f67fcecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraConfig {\n",
      "  \"_name_or_path\": \"/home/osung/models/huggingface/sentiment\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"0\",\n",
      "    \"1\": \"1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"0\": 0,\n",
      "    \"1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 35000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7391708a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 완벽해요\n",
      "Predicted Sentiment: 1 (Score: 0.5388)\n",
      "All Scores: {'0': 0.4612140655517578, '1': 0.5387859344482422}\n"
     ]
    }
   ],
   "source": [
    "classify_sentiment('완벽해요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "91854679",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"“교육·교통·문화 모두 갖춘 강남 최고의 입지” 지상 38층·지하 3층에 15개동 1,612세대 중 일반분양 213세대 한강 조망권·주거환경 등 호평 모델하우스 수요자 발길 줄이어 9·1 부동산대책 발표 후 강남 재건축단지의 몸값이 나날이 높아지고 있는 가운데 서울 강남권 재건축 아파트 중 신반포1차를 재건축한 `아크로리버 파크 2회차'가 9·1 대책 발표 후 가장 먼저 분양에 나서면서 고액 자산가들의 관심이 집중되고 있다. 강남 최고 부촌 아파트를 넘보는 대림산업의 `아크로리버 파크 2회차'가 지난 19일 견본주택의 문을 열고 본격 분양에 들어갔다. 단지는 지하 3층~지상 38층, 15개 동, 전용면적 59~164㎡로 전체 1,612세대 중 213세대가 일반 분양된다. 세부면적을 살펴보면, △59㎡ 40세대 △84㎡ 118세대 △112㎡ 16세대 △129㎡ 33세대 △164㎡ 6세대로 중소형이 74%를 차지한다. 입주시기는 2016년 8월 예정이다. ■반포지구 재건축단지 중 최고 층수로 지어져 … 반포지역 프리미엄 톡톡=반포 `아크로리버 파크'는 교육, 교통, 문화, 편의시설 등 완벽한 주거환경을 갖춰 대표 부촌으로 자리를 굳히고 있는 반포의 중심에 위치하는 만큼 지역 프리미엄을 톡톡히 누릴 수 있는 곳이다. 또한 이 단지는 강남 한강변에 10년 만에 공급된 아파트인데다 강남 한강변에서는 최초로 특별건축구역으로 지정돼 최고 38층 초고층으로 건설된다. 다른 반포지구 재건축단지 최고 층수는 34~35층으로 향후 반포동 랜드마크 단지로서의 역할이 기대된다. ■한강 조망 가능한 `고층 중심', 대리석 마감 및 독일산 주방가구로 `상품 업그레이드'=아크로리버 파크 2회차의 분양가는 현재 서초구에서 가장 고가 아파트이며 입주 5년차를 맞은 `래미안퍼스티지'의 전용 59㎡가 8억9,000만~10억5,000만원 사이에 거래되는 것과 비교해 비슷한 수준에 책정됐다. 아크로리버파크 2회차 총 분양가는 전용 59㎡가 8억4,900만~10억5,000만원, 전용 84㎡는 11억8,000만~15억4,500만원선으로 책정됐다. 전용 112㎡는 16억3,000만~20억1,000만원, 전용 129㎡ 18억~21억4,000만원, 전용 164㎡는 21억8,000만~23억9,000만원이다. 계약조건은 계약금 10%, 중도금 이자 후불제가 적용된다. ■최고 부촌에 지어지는 최고가 명품 아파트답게 고급화된 설계 눈길=반포 `아크로리버 파크'가 강남 노른자위에 지어지는 최고가 명품 단지인 만큼 2회차 물량에도 최고급 설계가 적용된다. 우선 동 배치를 오픈 뷰(Open view)와 59m의 동 간 이격 거리로 실현해 탁 트인 조망권과 풍부한 일조권을 확보했다. 또한 단지 내 6개 테마정원뿐만 아니라 서측공원과 보행로를 따라 한강시민공원 반포지구까지 연결돼 있어 쾌적한 주거환경을 갖췄으며, 단지 내에서도 메인 커뮤니티 및 지하철 접근성이 우수한 것도 특징으로 꼽힌다. 견본주택은 서울 강남구 신사동 631 도산공원 사거리에서 성수대교 남단 교차로 방면 우측에 있다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5e8b914b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1492"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6ee6b2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: “교육·교통·문화 모두 갖춘 강남 최고의 입지” 지상 38층·지하 3층에 15개동 1,612세대 중 일반분양 213세대 한강 조망권·주거환경 등 호평 모델하우스 수요자 발길 줄이어 9·1 부동산대책 발표 후 강남 재건축단지의 몸값이 나날이 높아지고 있는 가운데 서울 강남권 재건축 아파트 중 신반포1차를 재건축한 `아크로리버 파크 2회차'가 9·1 대책 발표 후 가장 먼저 분양에 나서면서 고액 자산가들의 관심이 집중되고 있다. 강남 최고 부촌 아파트를 넘보는 대림산업의 `아크로리버 파크 2회차'가 지난 19일 견본주택의 문을 열고 본격 분양에 들어갔다. 단지는 지하 3층~지상 38층, 15개 동, 전용면적 59~164㎡로 전체 1,612세대 중 213세대가 일반 분양된다. 세부면적을 살펴보면, △59㎡ 40세대 △84㎡ 118세대 △112㎡ 16세대 △129㎡ 33세대 △164㎡ 6세대로 중소형이 74%를 차지한다. 입주시기는 2016년 8월 예정이다. ■반포지구 재건축단지 중 최고 층수로 지어져 … 반포지역 프리미엄 톡톡=반포 `아크로리버 파크'는 교육, 교통, 문화, 편의시설 등 완벽한 주거환경을 갖춰 대표 부촌으로 자리를 굳히고 있는 반포의 중심에 위치하는 만큼 지역 프리미엄을 톡톡히 누릴 수 있는 곳이다. 또한 이 단지는 강남 한강변에 10년 만에 공급된 아파트인데다 강남 한강변에서는 최초로 특별건축구역으로 지정돼 최고 38층 초고층으로 건설된다. 다른 반포지구 재건축단지 최고 층수는 34~35층으로 향후 반포동 랜드마크 단지로서의 역할이 기대된다. ■한강 조망 가능한 `고층 중심', 대리석 마감 및 독일산 주방가구로 `상품 업그레이드'=아크로리버 파크 2회차의 분양가는 현재 서초구에서 가장 고가 아파트이며 입주 5년차를 맞은 `래미안퍼스티지'의 전용 59㎡가 8억9,000만~10억5,000만원 사이에 거래되는 것과 비교해 비슷한 수준에 책정됐다. 아크로리버파크 2회차 총 분양가는 전용 59㎡가 8억4,900만~10억5,000만원, 전용 84㎡는 11억8,000만~15억4,500만원선으로 책정됐다. 전용 112㎡는 16억3,000만~20억1,000만원, 전용 129㎡ 18억~21억4,000만원, 전용 164㎡는 21억8,000만~23억9,000만원이다. 계약조건은 계약금 10%, 중도금 이자 후불제가 적용된다. ■최고 부촌에 지어지는 최고가 명품 아파트답게 고급화된 설계 눈길=반포 `아크로리버 파크'가 강남 노른자위에 지어지는 최고가 명품 단지인 만큼 2회차 물량에도 최고급 설계가 적용된다. 우선 동 배치를 오픈 뷰(Open view)와 59m의 동 간 이격 거리로 실현해 탁 트인 조망권과 풍부한 일조권을 확보했다. 또한 단지 내 6개 테마정원뿐만 아니라 서측공원과 보행로를 따라 한강시민공원 반포지구까지 연결돼 있어 쾌적한 주거환경을 갖췄으며, 단지 내에서도 메인 커뮤니티 및 지하철 접근성이 우수한 것도 특징으로 꼽힌다. 견본주택은 서울 강남구 신사동 631 도산공원 사거리에서 성수대교 남단 교차로 방면 우측에 있다.\n",
      "Predicted Sentiment: 1 (Score: 0.5275)\n",
      "All Scores: {'0': 0.472453773021698, '1': 0.5275461673736572}\n"
     ]
    }
   ],
   "source": [
    "classify_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cdf872d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '허태열 대통령비서실장이 최근 수석비서관회의를 주재하면서 웬만하면 필드골프장 대신 스크린골프를 이용하는 게 좋겠다고 말한 것으로 전해졌다. 2월 박근혜 정부 출범 이후 골프 금지령이 내려진 적은 없지만 북한의 위협이 이어진 데다 정권 출범의 긴장감이 더해져 공직자들은 자연스레 골프를 칠 엄두를 내지 못했다. 이와 관련해 박 대통령은 10일 언론사 논설실장 오찬에서 캐디들도 수입이 그렇고 자꾸 외국만 나가서 어떻게 하느냐고 걱정하는 이야기도 있다 지금 여러 가지 생각을 하고 있다고 밝혔다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "45819251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f8adfb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 허태열 대통령비서실장이 최근 수석비서관회의를 주재하면서 웬만하면 필드골프장 대신 스크린골프를 이용하는 게 좋겠다고 말한 것으로 전해졌다. 2월 박근혜 정부 출범 이후 골프 금지령이 내려진 적은 없지만 북한의 위협이 이어진 데다 정권 출범의 긴장감이 더해져 공직자들은 자연스레 골프를 칠 엄두를 내지 못했다. 이와 관련해 박 대통령은 10일 언론사 논설실장 오찬에서 캐디들도 수입이 그렇고 자꾸 외국만 나가서 어떻게 하느냐고 걱정하는 이야기도 있다 지금 여러 가지 생각을 하고 있다고 밝혔다.\n",
      "Predicted Sentiment: 0 (Score: 0.5309)\n",
      "All Scores: {'0': 0.5309069752693176, '1': 0.46909299492836}\n"
     ]
    }
   ],
   "source": [
    "classify_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "34811217",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"문재인 대통령은 9일 오후 청와대 상춘재에서 진행된 KBS '문재인 정부 2년 특집 대담, 대통령에게 묻는다'에 출연해, 정부 출범 2주년 소회 및 각 분야별 입장을 밝혔다. 그래서 문재인 정부는 촛불정신 위에 서 있다. 촛불민심이 명하는 대로 국정농단, 그리고 반칙과 특권이라는 적폐시대를 마감하고, 새로운 시대, 공정하고 정의로운 대한민국의 길을 향해서 걸어가고 있다.그래서 그 해법을 선택한 것을 가지고 독재라 하는 것은 정말 조금 맞지 않는 얘기란 말씀을 드린다. 검찰 스스로 개혁을 할 수 있는 많은 기회들을 지금까지 놓쳐 왔다. 그래서 검찰은 개혁의 당사자이고, 말하자면 이제는 셀프개혁으로서는 안 된다는 게 국민들의 보편적인 생각이기 때문에 그런 방안들이 마련되고 있는 것이어서 검찰이 보다 좀 겸허한 자세를 가져야한다고 생각한다.북한이 며칠 전에 여러 종류의 단거리 발사체를 발사한 데 이어서 오늘은 일단 단거리 미사일로 추정되는 그런 발사를 했다. 유엔 안보리 결의 속에는 탄도미사일을 하지 말라는 그런 표현이 있기 때문에 비록 단거리라 할지라도 그것이 탄도미사일일 경우에는 유엔안보리 결의에 위반될 소지도 없지 않다고 생각한다. 그런 방식으로 북한의 의도를 여러 가지로 해석하게 만들고 또 우려하게 만들고 자칫 잘못하면 대화와 협상국면의 찻물을 끼얹는 이런 성격을 거듭 하는 것은 결코 바람직하지 않다는 것을 북한측에 다시 한 번 이야기하고 싶다. 그런 형편이기 때문에 북한동포들의 심각한 기아상태를 우리가 외면할 수 없고, 우리가 동포애나 인도주의적인 차원에서라도 우리가 북한의 식량을 지원할 필요가 있다고 생각하는 것이다.북한의 식량지원 문제에 대해서 저로서는 가장 바람직한 것은 지금 패스트트랙 문제 때문에 여야 간 정국이 교착상태에 빠져 있는데 그 문제는 별도로 해결하더라도 북한에 대한 식량지원에 대해서는 대통령과 여야가 함께 모여서 협의를 하는 것이 바람직하지 않을까 라는 생각을 하고 있다. 그래서 그렇기 때문에 사실은 식량지원의 문제에 대해서 우리가 한미간에 합의를 한 것이 이번 발사 이전인데, 그 이후에 또 다시 발사가 있었기 때문에 이 점에 대해서는 국민들의 공감이나 제재가 필요하다고 생각한다. 한일관계는 굉장히 중요하다고 생각하고, 앞으로 더 미래지향적으로 발전돼 나가야 한다고 생각한다.고령화가 급격하게 진행되고 있어서 65세 이상 인구가 14%가 넘는 고령사회를 이미 2017년에 통과했고, 2025년이면 20%가 넘는 초고령사회가 될 것으로 예상된다. 고령인구가 크게 늘고 있기 때문에 일자리 수를 더 늘리고 과거의 급여가 낮았기 때문에 급여를 두배 높여서 실제로 어르신들의 빈곤 해결에 도움되도록 정부가 노력하고 있는 것이다. 거시적인 경제성공은 인정하고 자부심을 가져야 한다고 생각한다. 다만 국민들에게 고르게 다 소득배분이 되고 있지 않고 있기 때문에 아직도 양극화가 심각하고 특히 소득이 낮은 층의 소득이 늘지 않고 있기때문에 그분들의 사는 문제가 해결이 안 되고 있다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8b24d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 문재인 대통령은 9일 오후 청와대 상춘재에서 진행된 KBS '문재인 정부 2년 특집 대담, 대통령에게 묻는다'에 출연해, 정부 출범 2주년 소회 및 각 분야별 입장을 밝혔다. 그래서 문재인 정부는 촛불정신 위에 서 있다. 촛불민심이 명하는 대로 국정농단, 그리고 반칙과 특권이라는 적폐시대를 마감하고, 새로운 시대, 공정하고 정의로운 대한민국의 길을 향해서 걸어가고 있다.그래서 그 해법을 선택한 것을 가지고 독재라 하는 것은 정말 조금 맞지 않는 얘기란 말씀을 드린다. 검찰 스스로 개혁을 할 수 있는 많은 기회들을 지금까지 놓쳐 왔다. 그래서 검찰은 개혁의 당사자이고, 말하자면 이제는 셀프개혁으로서는 안 된다는 게 국민들의 보편적인 생각이기 때문에 그런 방안들이 마련되고 있는 것이어서 검찰이 보다 좀 겸허한 자세를 가져야한다고 생각한다.북한이 며칠 전에 여러 종류의 단거리 발사체를 발사한 데 이어서 오늘은 일단 단거리 미사일로 추정되는 그런 발사를 했다. 유엔 안보리 결의 속에는 탄도미사일을 하지 말라는 그런 표현이 있기 때문에 비록 단거리라 할지라도 그것이 탄도미사일일 경우에는 유엔안보리 결의에 위반될 소지도 없지 않다고 생각한다. 그런 방식으로 북한의 의도를 여러 가지로 해석하게 만들고 또 우려하게 만들고 자칫 잘못하면 대화와 협상국면의 찻물을 끼얹는 이런 성격을 거듭 하는 것은 결코 바람직하지 않다는 것을 북한측에 다시 한 번 이야기하고 싶다. 그런 형편이기 때문에 북한동포들의 심각한 기아상태를 우리가 외면할 수 없고, 우리가 동포애나 인도주의적인 차원에서라도 우리가 북한의 식량을 지원할 필요가 있다고 생각하는 것이다.북한의 식량지원 문제에 대해서 저로서는 가장 바람직한 것은 지금 패스트트랙 문제 때문에 여야 간 정국이 교착상태에 빠져 있는데 그 문제는 별도로 해결하더라도 북한에 대한 식량지원에 대해서는 대통령과 여야가 함께 모여서 협의를 하는 것이 바람직하지 않을까 라는 생각을 하고 있다. 그래서 그렇기 때문에 사실은 식량지원의 문제에 대해서 우리가 한미간에 합의를 한 것이 이번 발사 이전인데, 그 이후에 또 다시 발사가 있었기 때문에 이 점에 대해서는 국민들의 공감이나 제재가 필요하다고 생각한다. 한일관계는 굉장히 중요하다고 생각하고, 앞으로 더 미래지향적으로 발전돼 나가야 한다고 생각한다.고령화가 급격하게 진행되고 있어서 65세 이상 인구가 14%가 넘는 고령사회를 이미 2017년에 통과했고, 2025년이면 20%가 넘는 초고령사회가 될 것으로 예상된다. 고령인구가 크게 늘고 있기 때문에 일자리 수를 더 늘리고 과거의 급여가 낮았기 때문에 급여를 두배 높여서 실제로 어르신들의 빈곤 해결에 도움되도록 정부가 노력하고 있는 것이다. 거시적인 경제성공은 인정하고 자부심을 가져야 한다고 생각한다. 다만 국민들에게 고르게 다 소득배분이 되고 있지 않고 있기 때문에 아직도 양극화가 심각하고 특히 소득이 낮은 층의 소득이 늘지 않고 있기때문에 그분들의 사는 문제가 해결이 안 되고 있다.\n",
      "Predicted Sentiment: 0 (Score: 0.5315)\n",
      "All Scores: {'0': 0.5314578413963318, '1': 0.4685421288013458}\n"
     ]
    }
   ],
   "source": [
    "classify_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1e4e05b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/home/osung/data/korean/finance/finance_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "64ec7bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>이 회사는 러시아의 톰스크 지역에 있는 베니어 공장에 기계를 납품하기로 되어 있었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>UNC 샬롯은 또한 SSH Tetia Connector를 배포하여 안전한 응용 프로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2009년에 리앤맨은 연간 450만 톤의 종이와 300,000 톤의 펄프를 생산할 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>`` 그러나 핀란드 관광객들이 구매한 맥주도 포함돼 있다는 점을 상기하며 유럽 규모...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>핀란드에서는 알마미디어의 Etuovi.com이 해당 서비스를 제공하고 있는데, 이는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2006년과 2007년의 총 투자액은 약 75만 유로에 달할 것으로 예상됩니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>0.5</td>\n",
       "      <td>그 확장된 회사는 계속해서 NewPage로 불릴 것이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>0.5</td>\n",
       "      <td>금요일에 활성화되도록 설정된 웜은 '를 포함하여 가장 일반적인 파일 형식을 사용하여...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0.5</td>\n",
       "      <td>장비는 핀란드 홀롤라에 있는 Vahto의 작업장에서 생산될 예정이며 2009년 1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1.0</td>\n",
       "      <td>영업이익은 2007년 같은 기간의 17.6 mn에 비해 총 17.7 mn입니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1454 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                               text\n",
       "0        0.5    이 회사는 러시아의 톰스크 지역에 있는 베니어 공장에 기계를 납품하기로 되어 있었다.\n",
       "1        0.5  UNC 샬롯은 또한 SSH Tetia Connector를 배포하여 안전한 응용 프로...\n",
       "2        0.5  2009년에 리앤맨은 연간 450만 톤의 종이와 300,000 톤의 펄프를 생산할 ...\n",
       "3        0.5  `` 그러나 핀란드 관광객들이 구매한 맥주도 포함돼 있다는 점을 상기하며 유럽 규모...\n",
       "4        0.5  핀란드에서는 알마미디어의 Etuovi.com이 해당 서비스를 제공하고 있는데, 이는...\n",
       "...      ...                                                ...\n",
       "1449     0.5       2006년과 2007년의 총 투자액은 약 75만 유로에 달할 것으로 예상됩니다.\n",
       "1450     0.5                    그 확장된 회사는 계속해서 NewPage로 불릴 것이다.\n",
       "1451     0.5  금요일에 활성화되도록 설정된 웜은 '를 포함하여 가장 일반적인 파일 형식을 사용하여...\n",
       "1452     0.5  장비는 핀란드 홀롤라에 있는 Vahto의 작업장에서 생산될 예정이며 2009년 1/...\n",
       "1453     1.0       영업이익은 2007년 같은 기간의 17.6 mn에 비해 총 17.7 mn입니다.\n",
       "\n",
       "[1454 rows x 2 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0ace3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for text in test_df.text:\n",
    "    result = get_sentiment(text)\n",
    "    results.append(result)\n",
    "    \n",
    "test_df['result'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7340c2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5164045691490173"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(test_df.iloc[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6f6c4bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>이 회사는 러시아의 톰스크 지역에 있는 베니어 공장에 기계를 납품하기로 되어 있었다.</td>\n",
       "      <td>0.516405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>UNC 샬롯은 또한 SSH Tetia Connector를 배포하여 안전한 응용 프로...</td>\n",
       "      <td>0.522234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2009년에 리앤맨은 연간 450만 톤의 종이와 300,000 톤의 펄프를 생산할 ...</td>\n",
       "      <td>0.519056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>`` 그러나 핀란드 관광객들이 구매한 맥주도 포함돼 있다는 점을 상기하며 유럽 규모...</td>\n",
       "      <td>0.515279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>핀란드에서는 알마미디어의 Etuovi.com이 해당 서비스를 제공하고 있는데, 이는...</td>\n",
       "      <td>0.522005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2006년과 2007년의 총 투자액은 약 75만 유로에 달할 것으로 예상됩니다.</td>\n",
       "      <td>0.529533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>0.5</td>\n",
       "      <td>그 확장된 회사는 계속해서 NewPage로 불릴 것이다.</td>\n",
       "      <td>0.521242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>0.5</td>\n",
       "      <td>금요일에 활성화되도록 설정된 웜은 '를 포함하여 가장 일반적인 파일 형식을 사용하여...</td>\n",
       "      <td>0.520972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0.5</td>\n",
       "      <td>장비는 핀란드 홀롤라에 있는 Vahto의 작업장에서 생산될 예정이며 2009년 1/...</td>\n",
       "      <td>0.507534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1.0</td>\n",
       "      <td>영업이익은 2007년 같은 기간의 17.6 mn에 비해 총 17.7 mn입니다.</td>\n",
       "      <td>0.520121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1454 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                               text    result\n",
       "0        0.5    이 회사는 러시아의 톰스크 지역에 있는 베니어 공장에 기계를 납품하기로 되어 있었다.  0.516405\n",
       "1        0.5  UNC 샬롯은 또한 SSH Tetia Connector를 배포하여 안전한 응용 프로...  0.522234\n",
       "2        0.5  2009년에 리앤맨은 연간 450만 톤의 종이와 300,000 톤의 펄프를 생산할 ...  0.519056\n",
       "3        0.5  `` 그러나 핀란드 관광객들이 구매한 맥주도 포함돼 있다는 점을 상기하며 유럽 규모...  0.515279\n",
       "4        0.5  핀란드에서는 알마미디어의 Etuovi.com이 해당 서비스를 제공하고 있는데, 이는...  0.522005\n",
       "...      ...                                                ...       ...\n",
       "1449     0.5       2006년과 2007년의 총 투자액은 약 75만 유로에 달할 것으로 예상됩니다.  0.529533\n",
       "1450     0.5                    그 확장된 회사는 계속해서 NewPage로 불릴 것이다.  0.521242\n",
       "1451     0.5  금요일에 활성화되도록 설정된 웜은 '를 포함하여 가장 일반적인 파일 형식을 사용하여...  0.520972\n",
       "1452     0.5  장비는 핀란드 홀롤라에 있는 Vahto의 작업장에서 생산될 예정이며 2009년 1/...  0.507534\n",
       "1453     1.0       영업이익은 2007년 같은 기간의 17.6 mn에 비해 총 17.7 mn입니다.  0.520121\n",
       "\n",
       "[1454 rows x 3 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "54c96c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['diff'] = test_df['labels'] - test_df['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "034f628b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.016405\n",
       "1      -0.022234\n",
       "2      -0.019056\n",
       "3      -0.015279\n",
       "4      -0.022005\n",
       "          ...   \n",
       "1449   -0.029533\n",
       "1450   -0.021242\n",
       "1451   -0.020972\n",
       "1452   -0.007534\n",
       "1453    0.479879\n",
       "Name: diff, Length: 1454, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "58a6a774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1454.000000\n",
       "mean        0.072133\n",
       "std         0.310558\n",
       "min        -0.529161\n",
       "25%        -0.018837\n",
       "50%        -0.008421\n",
       "75%         0.474849\n",
       "max         0.499910\n",
       "Name: diff, dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0110e41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1454.000000\n",
       "mean        0.513493\n",
       "std         0.008031\n",
       "min         0.500023\n",
       "25%         0.506944\n",
       "50%         0.512960\n",
       "75%         0.519241\n",
       "max         0.536858\n",
       "Name: result, dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['result'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5d81c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for text in test_df.text:\n",
    "    result = int(classify_sentiment(text))\n",
    "    results.append(result)\n",
    "    \n",
    "test_df['class'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2820364f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>result</th>\n",
       "      <th>diff</th>\n",
       "      <th>class</th>\n",
       "      <th>diff2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>이 회사는 러시아의 톰스크 지역에 있는 베니어 공장에 기계를 납품하기로 되어 있었다.</td>\n",
       "      <td>0.516405</td>\n",
       "      <td>-0.016405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>UNC 샬롯은 또한 SSH Tetia Connector를 배포하여 안전한 응용 프로...</td>\n",
       "      <td>0.522234</td>\n",
       "      <td>-0.022234</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2009년에 리앤맨은 연간 450만 톤의 종이와 300,000 톤의 펄프를 생산할 ...</td>\n",
       "      <td>0.519056</td>\n",
       "      <td>-0.019056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>`` 그러나 핀란드 관광객들이 구매한 맥주도 포함돼 있다는 점을 상기하며 유럽 규모...</td>\n",
       "      <td>0.515279</td>\n",
       "      <td>-0.015279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>핀란드에서는 알마미디어의 Etuovi.com이 해당 서비스를 제공하고 있는데, 이는...</td>\n",
       "      <td>0.522005</td>\n",
       "      <td>-0.022005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2006년과 2007년의 총 투자액은 약 75만 유로에 달할 것으로 예상됩니다.</td>\n",
       "      <td>0.529533</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>0.5</td>\n",
       "      <td>그 확장된 회사는 계속해서 NewPage로 불릴 것이다.</td>\n",
       "      <td>0.521242</td>\n",
       "      <td>-0.021242</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>0.5</td>\n",
       "      <td>금요일에 활성화되도록 설정된 웜은 '를 포함하여 가장 일반적인 파일 형식을 사용하여...</td>\n",
       "      <td>0.479028</td>\n",
       "      <td>-0.020972</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0.5</td>\n",
       "      <td>장비는 핀란드 홀롤라에 있는 Vahto의 작업장에서 생산될 예정이며 2009년 1/...</td>\n",
       "      <td>0.507534</td>\n",
       "      <td>-0.007534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1.0</td>\n",
       "      <td>영업이익은 2007년 같은 기간의 17.6 mn에 비해 총 17.7 mn입니다.</td>\n",
       "      <td>0.520121</td>\n",
       "      <td>0.479879</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1454 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                               text    result  \\\n",
       "0        0.5    이 회사는 러시아의 톰스크 지역에 있는 베니어 공장에 기계를 납품하기로 되어 있었다.  0.516405   \n",
       "1        0.5  UNC 샬롯은 또한 SSH Tetia Connector를 배포하여 안전한 응용 프로...  0.522234   \n",
       "2        0.5  2009년에 리앤맨은 연간 450만 톤의 종이와 300,000 톤의 펄프를 생산할 ...  0.519056   \n",
       "3        0.5  `` 그러나 핀란드 관광객들이 구매한 맥주도 포함돼 있다는 점을 상기하며 유럽 규모...  0.515279   \n",
       "4        0.5  핀란드에서는 알마미디어의 Etuovi.com이 해당 서비스를 제공하고 있는데, 이는...  0.522005   \n",
       "...      ...                                                ...       ...   \n",
       "1449     0.5       2006년과 2007년의 총 투자액은 약 75만 유로에 달할 것으로 예상됩니다.  0.529533   \n",
       "1450     0.5                    그 확장된 회사는 계속해서 NewPage로 불릴 것이다.  0.521242   \n",
       "1451     0.5  금요일에 활성화되도록 설정된 웜은 '를 포함하여 가장 일반적인 파일 형식을 사용하여...  0.479028   \n",
       "1452     0.5  장비는 핀란드 홀롤라에 있는 Vahto의 작업장에서 생산될 예정이며 2009년 1/...  0.507534   \n",
       "1453     1.0       영업이익은 2007년 같은 기간의 17.6 mn에 비해 총 17.7 mn입니다.  0.520121   \n",
       "\n",
       "          diff  class  diff2  \n",
       "0    -0.016405      1    0.5  \n",
       "1    -0.022234      1    0.5  \n",
       "2    -0.019056      1    0.5  \n",
       "3    -0.015279      1    0.5  \n",
       "4    -0.022005      1    0.5  \n",
       "...        ...    ...    ...  \n",
       "1449 -0.029533      1    0.5  \n",
       "1450 -0.021242      1    0.5  \n",
       "1451 -0.020972      0   -0.5  \n",
       "1452 -0.007534      1    0.5  \n",
       "1453  0.479879      1    0.0  \n",
       "\n",
       "[1454 rows x 6 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5cf481bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1032\n",
       "0     422\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a95db2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['diff2'] = test_df['class'] - test_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d5b629d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1454.000000\n",
       "mean        0.124140\n",
       "std         0.434524\n",
       "min        -1.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.500000\n",
       "max         1.000000\n",
       "Name: diff2, dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['diff2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "866c72ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.5\n",
       "1       0.5\n",
       "2       0.5\n",
       "3       0.5\n",
       "4       0.5\n",
       "       ... \n",
       "1449    0.5\n",
       "1450    0.5\n",
       "1451   -0.5\n",
       "1452    0.5\n",
       "1453    0.0\n",
       "Name: diff2, Length: 1454, dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['diff2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6c5e36a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>result</th>\n",
       "      <th>diff</th>\n",
       "      <th>class</th>\n",
       "      <th>diff2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>이 회사는 러시아의 톰스크 지역에 있는 베니어 공장에 기계를 납품하기로 되어 있었다.</td>\n",
       "      <td>0.516405</td>\n",
       "      <td>-0.016405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>UNC 샬롯은 또한 SSH Tetia Connector를 배포하여 안전한 응용 프로...</td>\n",
       "      <td>0.522234</td>\n",
       "      <td>-0.022234</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2009년에 리앤맨은 연간 450만 톤의 종이와 300,000 톤의 펄프를 생산할 ...</td>\n",
       "      <td>0.519056</td>\n",
       "      <td>-0.019056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>`` 그러나 핀란드 관광객들이 구매한 맥주도 포함돼 있다는 점을 상기하며 유럽 규모...</td>\n",
       "      <td>0.515279</td>\n",
       "      <td>-0.015279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>핀란드에서는 알마미디어의 Etuovi.com이 해당 서비스를 제공하고 있는데, 이는...</td>\n",
       "      <td>0.522005</td>\n",
       "      <td>-0.022005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>공사는 2007년 4월부터 6월까지 시작되어 2008년 초에 완공될 예정이다.</td>\n",
       "      <td>0.506076</td>\n",
       "      <td>-0.006076</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>핀란드 소유의 전자제품 계약 제조업체인 Elcoteq Hungary Kft는 회사가...</td>\n",
       "      <td>0.513823</td>\n",
       "      <td>0.486177</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>이노바 2 프로젝트의 총 면적은 약 10,000 sq m (107,600 sq ft...</td>\n",
       "      <td>0.512156</td>\n",
       "      <td>-0.012156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>핀란드의 가정 장식 및 예술 공예 소매업체 티이마리(Tiimari Plc, OMX ...</td>\n",
       "      <td>0.482384</td>\n",
       "      <td>-0.017616</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>납품은 2007년 하반기에 시작될 것이며, 제분소의 시작은 2008년에 예정되어 있다.</td>\n",
       "      <td>0.483860</td>\n",
       "      <td>-0.016140</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2002년 설립된 스틱은 프랑스 남서부 보르도에 본사를 두고 있다.</td>\n",
       "      <td>0.507484</td>\n",
       "      <td>-0.007484</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>아우토텍은 1년 전 240.4mln유로에 비해 4분기 중 492.9mln유로를 신규...</td>\n",
       "      <td>0.517018</td>\n",
       "      <td>0.482982</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>이 매장은 포즈난에 위치한 페스트카라는 이름의 쇼핑센터에 위치하고 있다고 회사는 덧...</td>\n",
       "      <td>0.519975</td>\n",
       "      <td>-0.019975</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>주문 금액은 USD 2.2 mn입니다.</td>\n",
       "      <td>0.493508</td>\n",
       "      <td>-0.006492</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>그 회사는 2011년에도 고기 구매량이 약 800만 킬로에 머물 것으로 예상하고 있다.</td>\n",
       "      <td>0.506223</td>\n",
       "      <td>-0.006223</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>핀란드 주택제조업체들이 러시아에서 강하게 성장하고 있는 1가구 1주택 시장을 공략하...</td>\n",
       "      <td>0.507556</td>\n",
       "      <td>-0.007556</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "      <td>그 거래의 가치는 약 1.2 유로였습니다.</td>\n",
       "      <td>0.490583</td>\n",
       "      <td>-0.009417</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>이 커뮤니케이션과 관련된 모든 투자 또는 투자 활동은 관련자만 이용할 수 있으며 관...</td>\n",
       "      <td>0.500425</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.5</td>\n",
       "      <td>회사 증가에 따라+뉳UR TM의 자본금은 루마니아 레이 달러 1.98mln-1.56...</td>\n",
       "      <td>0.499687</td>\n",
       "      <td>-0.000313</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>협회 자료는 100여개 소규모 맥주회사의 매출액과 수입맥주 제품 판매량을 포함하지 ...</td>\n",
       "      <td>0.511954</td>\n",
       "      <td>-0.511954</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels                                               text    result  \\\n",
       "0      0.5    이 회사는 러시아의 톰스크 지역에 있는 베니어 공장에 기계를 납품하기로 되어 있었다.  0.516405   \n",
       "1      0.5  UNC 샬롯은 또한 SSH Tetia Connector를 배포하여 안전한 응용 프로...  0.522234   \n",
       "2      0.5  2009년에 리앤맨은 연간 450만 톤의 종이와 300,000 톤의 펄프를 생산할 ...  0.519056   \n",
       "3      0.5  `` 그러나 핀란드 관광객들이 구매한 맥주도 포함돼 있다는 점을 상기하며 유럽 규모...  0.515279   \n",
       "4      0.5  핀란드에서는 알마미디어의 Etuovi.com이 해당 서비스를 제공하고 있는데, 이는...  0.522005   \n",
       "5      0.5        공사는 2007년 4월부터 6월까지 시작되어 2008년 초에 완공될 예정이다.  0.506076   \n",
       "6      1.0  핀란드 소유의 전자제품 계약 제조업체인 Elcoteq Hungary Kft는 회사가...  0.513823   \n",
       "7      0.5  이노바 2 프로젝트의 총 면적은 약 10,000 sq m (107,600 sq ft...  0.512156   \n",
       "8      0.5  핀란드의 가정 장식 및 예술 공예 소매업체 티이마리(Tiimari Plc, OMX ...  0.482384   \n",
       "9      0.5   납품은 2007년 하반기에 시작될 것이며, 제분소의 시작은 2008년에 예정되어 있다.  0.483860   \n",
       "10     0.5              2002년 설립된 스틱은 프랑스 남서부 보르도에 본사를 두고 있다.  0.507484   \n",
       "11     1.0  아우토텍은 1년 전 240.4mln유로에 비해 4분기 중 492.9mln유로를 신규...  0.517018   \n",
       "12     0.5  이 매장은 포즈난에 위치한 페스트카라는 이름의 쇼핑센터에 위치하고 있다고 회사는 덧...  0.519975   \n",
       "13     0.5                              주문 금액은 USD 2.2 mn입니다.  0.493508   \n",
       "14     0.5   그 회사는 2011년에도 고기 구매량이 약 800만 킬로에 머물 것으로 예상하고 있다.  0.506223   \n",
       "15     0.5  핀란드 주택제조업체들이 러시아에서 강하게 성장하고 있는 1가구 1주택 시장을 공략하...  0.507556   \n",
       "16     0.5                            그 거래의 가치는 약 1.2 유로였습니다.  0.490583   \n",
       "17     0.5  이 커뮤니케이션과 관련된 모든 투자 또는 투자 활동은 관련자만 이용할 수 있으며 관...  0.500425   \n",
       "18     0.5  회사 증가에 따라+뉳UR TM의 자본금은 루마니아 레이 달러 1.98mln-1.56...  0.499687   \n",
       "19     0.0  협회 자료는 100여개 소규모 맥주회사의 매출액과 수입맥주 제품 판매량을 포함하지 ...  0.511954   \n",
       "\n",
       "        diff  class  diff2  \n",
       "0  -0.016405      1    0.5  \n",
       "1  -0.022234      1    0.5  \n",
       "2  -0.019056      1    0.5  \n",
       "3  -0.015279      1    0.5  \n",
       "4  -0.022005      1    0.5  \n",
       "5  -0.006076      1    0.5  \n",
       "6   0.486177      1    0.0  \n",
       "7  -0.012156      1    0.5  \n",
       "8  -0.017616      0   -0.5  \n",
       "9  -0.016140      0   -0.5  \n",
       "10 -0.007484      1    0.5  \n",
       "11  0.482982      1    0.0  \n",
       "12 -0.019975      1    0.5  \n",
       "13 -0.006492      0   -0.5  \n",
       "14 -0.006223      1    0.5  \n",
       "15 -0.007556      1    0.5  \n",
       "16 -0.009417      0   -0.5  \n",
       "17 -0.000425      1    0.5  \n",
       "18 -0.000313      0   -0.5  \n",
       "19 -0.511954      1    1.0  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "113d8db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 핀란드의 가정 장식 및 예술 공예 소매업체 티이마리(Tiimari Plc, OMX 헬싱키: TII1V)는 월요일 (8월 18일) 2008년 1월부터 6월까지의 순매출액 33.9m로 3.3m의 영업손실을 기록했다고 보고했다.\n",
      "Predicted Sentiment: 0 (Score: 0.5176)\n",
      "All Scores: {'0': 0.5176163911819458, '1': 0.4823836386203766}\n"
     ]
    }
   ],
   "source": [
    "classify_sentiment_detail(test_df.iloc[8].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a9b6e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['length'] = test_df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "39d8e714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>result</th>\n",
       "      <th>diff</th>\n",
       "      <th>class</th>\n",
       "      <th>diff2</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>이 회사는 러시아의 톰스크 지역에 있는 베니어 공장에 기계를 납품하기로 되어 있었다.</td>\n",
       "      <td>0.516405</td>\n",
       "      <td>-0.016405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>UNC 샬롯은 또한 SSH Tetia Connector를 배포하여 안전한 응용 프로...</td>\n",
       "      <td>0.522234</td>\n",
       "      <td>-0.022234</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2009년에 리앤맨은 연간 450만 톤의 종이와 300,000 톤의 펄프를 생산할 ...</td>\n",
       "      <td>0.519056</td>\n",
       "      <td>-0.019056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>`` 그러나 핀란드 관광객들이 구매한 맥주도 포함돼 있다는 점을 상기하며 유럽 규모...</td>\n",
       "      <td>0.515279</td>\n",
       "      <td>-0.015279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>핀란드에서는 알마미디어의 Etuovi.com이 해당 서비스를 제공하고 있는데, 이는...</td>\n",
       "      <td>0.522005</td>\n",
       "      <td>-0.022005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2006년과 2007년의 총 투자액은 약 75만 유로에 달할 것으로 예상됩니다.</td>\n",
       "      <td>0.529533</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>0.5</td>\n",
       "      <td>그 확장된 회사는 계속해서 NewPage로 불릴 것이다.</td>\n",
       "      <td>0.521242</td>\n",
       "      <td>-0.021242</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>0.5</td>\n",
       "      <td>금요일에 활성화되도록 설정된 웜은 '를 포함하여 가장 일반적인 파일 형식을 사용하여...</td>\n",
       "      <td>0.479028</td>\n",
       "      <td>-0.020972</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0.5</td>\n",
       "      <td>장비는 핀란드 홀롤라에 있는 Vahto의 작업장에서 생산될 예정이며 2009년 1/...</td>\n",
       "      <td>0.507534</td>\n",
       "      <td>-0.007534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1.0</td>\n",
       "      <td>영업이익은 2007년 같은 기간의 17.6 mn에 비해 총 17.7 mn입니다.</td>\n",
       "      <td>0.520121</td>\n",
       "      <td>0.479879</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1454 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                               text    result  \\\n",
       "0        0.5    이 회사는 러시아의 톰스크 지역에 있는 베니어 공장에 기계를 납품하기로 되어 있었다.  0.516405   \n",
       "1        0.5  UNC 샬롯은 또한 SSH Tetia Connector를 배포하여 안전한 응용 프로...  0.522234   \n",
       "2        0.5  2009년에 리앤맨은 연간 450만 톤의 종이와 300,000 톤의 펄프를 생산할 ...  0.519056   \n",
       "3        0.5  `` 그러나 핀란드 관광객들이 구매한 맥주도 포함돼 있다는 점을 상기하며 유럽 규모...  0.515279   \n",
       "4        0.5  핀란드에서는 알마미디어의 Etuovi.com이 해당 서비스를 제공하고 있는데, 이는...  0.522005   \n",
       "...      ...                                                ...       ...   \n",
       "1449     0.5       2006년과 2007년의 총 투자액은 약 75만 유로에 달할 것으로 예상됩니다.  0.529533   \n",
       "1450     0.5                    그 확장된 회사는 계속해서 NewPage로 불릴 것이다.  0.521242   \n",
       "1451     0.5  금요일에 활성화되도록 설정된 웜은 '를 포함하여 가장 일반적인 파일 형식을 사용하여...  0.479028   \n",
       "1452     0.5  장비는 핀란드 홀롤라에 있는 Vahto의 작업장에서 생산될 예정이며 2009년 1/...  0.507534   \n",
       "1453     1.0       영업이익은 2007년 같은 기간의 17.6 mn에 비해 총 17.7 mn입니다.  0.520121   \n",
       "\n",
       "          diff  class  diff2  length  \n",
       "0    -0.016405      1    0.5      47  \n",
       "1    -0.022234      1    0.5      62  \n",
       "2    -0.019056      1    0.5      52  \n",
       "3    -0.015279      1    0.5      64  \n",
       "4    -0.022005      1    0.5      96  \n",
       "...        ...    ...    ...     ...  \n",
       "1449 -0.029533      1    0.5      44  \n",
       "1450 -0.021242      1    0.5      31  \n",
       "1451 -0.020972      0   -0.5      59  \n",
       "1452 -0.007534      1    0.5      63  \n",
       "1453  0.479879      1    0.0      44  \n",
       "\n",
       "[1454 rows x 7 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8757d03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1454.000000\n",
       "mean       60.698074\n",
       "std        28.355093\n",
       "min         6.000000\n",
       "25%        39.000000\n",
       "50%        55.000000\n",
       "75%        76.000000\n",
       "max       169.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7a19ef9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>result</th>\n",
       "      <th>diff</th>\n",
       "      <th>class</th>\n",
       "      <th>diff2</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>0.5</td>\n",
       "      <td>Proha Plc (Euronext :7327)는 오늘 (5월 19일) 완전 소유 ...</td>\n",
       "      <td>0.499300</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(ADP News ) - 2008년 11월 3일 - 핀란드 화물 처리 시스템 및 서...</td>\n",
       "      <td>0.505610</td>\n",
       "      <td>0.494390</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>0.5</td>\n",
       "      <td>기업 IT 업데이트 - ( C) 1995-2009 M2 Communications ...</td>\n",
       "      <td>0.504175</td>\n",
       "      <td>-0.004175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>0.5</td>\n",
       "      <td>노르딕 비즈니스 보고서-2006년 1월 17일-에포어 플럭스는 에스토니아에 새로운 ...</td>\n",
       "      <td>0.503659</td>\n",
       "      <td>-0.003659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KAUKO-TELKO LTD 보도 자료 19.06.27 14.00 1 ( 1) Te...</td>\n",
       "      <td>0.487515</td>\n",
       "      <td>0.487515</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>0.5</td>\n",
       "      <td>리오라가 새 가방을 가졌어</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>-0.013551</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0.5</td>\n",
       "      <td>누구나 환영합니다.</td>\n",
       "      <td>0.534867</td>\n",
       "      <td>-0.034867</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>0.5</td>\n",
       "      <td>넌 혼자가 아니야</td>\n",
       "      <td>0.504075</td>\n",
       "      <td>-0.004075</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.5</td>\n",
       "      <td>NWC 분석:</td>\n",
       "      <td>0.496722</td>\n",
       "      <td>-0.003278</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.5</td>\n",
       "      <td>환영합니다!</td>\n",
       "      <td>0.522867</td>\n",
       "      <td>-0.022867</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1454 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                               text    result  \\\n",
       "768      0.5  Proha Plc (Euronext :7327)는 오늘 (5월 19일) 완전 소유 ...  0.499300   \n",
       "940      1.0  (ADP News ) - 2008년 11월 3일 - 핀란드 화물 처리 시스템 및 서...  0.505610   \n",
       "1328     0.5  기업 IT 업데이트 - ( C) 1995-2009 M2 Communications ...  0.504175   \n",
       "839      0.5  노르딕 비즈니스 보고서-2006년 1월 17일-에포어 플럭스는 에스토니아에 새로운 ...  0.503659   \n",
       "707      1.0  KAUKO-TELKO LTD 보도 자료 19.06.27 14.00 1 ( 1) Te...  0.487515   \n",
       "...      ...                                                ...       ...   \n",
       "1094     0.5                                     리오라가 새 가방을 가졌어  0.513551   \n",
       "1258     0.5                                         누구나 환영합니다.  0.534867   \n",
       "1059     0.5                                          넌 혼자가 아니야  0.504075   \n",
       "510      0.5                                            NWC 분석:  0.496722   \n",
       "740      0.5                                             환영합니다!  0.522867   \n",
       "\n",
       "          diff  class  diff2  length  \n",
       "768  -0.000700      0   -0.5     169  \n",
       "940   0.494390      1    0.0     164  \n",
       "1328 -0.004175      1    0.5     160  \n",
       "839  -0.003659      1    0.5     158  \n",
       "707   0.487515      0   -1.0     157  \n",
       "...        ...    ...    ...     ...  \n",
       "1094 -0.013551      1    0.5      14  \n",
       "1258 -0.034867      1    0.5      10  \n",
       "1059 -0.004075      1    0.5       9  \n",
       "510  -0.003278      0   -0.5       7  \n",
       "740  -0.022867      1    0.5       6  \n",
       "\n",
       "[1454 rows x 7 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by='length', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c785a838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Proha Plc (Euronext :7327)는 오늘 (5월 19일) 완전 소유 자회사인 Safran Software Solutions AS가 노르웨이에 본사를 둔 투자 그룹인 SNA Holding AS에 49%의 Safran North America LLC 지분을 매각하기로 합의했다고 발표했습니다.'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[768].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "51862b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KAUKO-TELKO LTD 보도 자료 19.06.27 14.00 1 ( 1) Telko Group(Kauko-Telko)은 BP의 스웨덴 소매 회사인 Molub-Aloy AB의 총 소유권을 인수하여 BP 산업 윤활유 및 서비스(BP ILS)와 전략적 파트너십을 확장하고 있습니다.'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[707].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "925cb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/osung/data/korean/finance/finance_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b0d10fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2009년 영업이익은 이전에 발표된 전망보다 낮다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>레흐덴테키자트의 순매출은 2007년 약 1400만 유로였으며 70명의 직원을 두고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>지역 사회 정원 가꾸기는 특히 채소를 기르기 위한 인기 있는 활동이 되었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>알파 그룹은 신설 회사의 43.9%, 텔레노르는 35.4%의 자유 유동 주식을 보유...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>이 중 38.8 유로가 순이자 수익이었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>통화효과는 3.0pct, 즉 20mln 유로($31.3mln)로 수익에 부정적인 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>1.0</td>\n",
       "      <td>`` 리드스코에 피보의 투자 프로그램은 생산의 통합 현대화, 운송 및 물류 인프라 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>0.5</td>\n",
       "      <td>제품에는 휴대폰과 같은 가전 기기, 셋톱 박스, 평면 패널 TV뿐만 아니라 인프라 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>0.5</td>\n",
       "      <td>이 다리는 14번 고속도로 개발 프로젝트의 일부이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(ADP News ) - 2008년 10월 1일 - 핀란드 컨설팅 및 엔지니어링 회...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3392 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                               text\n",
       "0        0.0                       2009년 영업이익은 이전에 발표된 전망보다 낮다.\n",
       "1        0.5  레흐덴테키자트의 순매출은 2007년 약 1400만 유로였으며 70명의 직원을 두고 있다.\n",
       "2        0.5         지역 사회 정원 가꾸기는 특히 채소를 기르기 위한 인기 있는 활동이 되었다.\n",
       "3        0.5  알파 그룹은 신설 회사의 43.9%, 텔레노르는 35.4%의 자유 유동 주식을 보유...\n",
       "4        0.5                            이 중 38.8 유로가 순이자 수익이었다.\n",
       "...      ...                                                ...\n",
       "3387     0.0  통화효과는 3.0pct, 즉 20mln 유로($31.3mln)로 수익에 부정적인 영...\n",
       "3388     1.0  `` 리드스코에 피보의 투자 프로그램은 생산의 통합 현대화, 운송 및 물류 인프라 ...\n",
       "3389     0.5  제품에는 휴대폰과 같은 가전 기기, 셋톱 박스, 평면 패널 TV뿐만 아니라 인프라 ...\n",
       "3390     0.5                      이 다리는 14번 고속도로 개발 프로젝트의 일부이다.\n",
       "3391     1.0  (ADP News ) - 2008년 10월 1일 - 핀란드 컨설팅 및 엔지니어링 회...\n",
       "\n",
       "[3392 rows x 2 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3423b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "60d99f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_id = self.input_ids[idx]\n",
    "        attention_mask = self.attention_masks[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return input_id, attention_mask, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7ae74de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encode_data(tokenizer, sentences, labels, max_length=512):\n",
    "    encoded_inputs = tokenizer(sentences, padding=True, truncation=True, max_length=max_length)\n",
    "    input_ids = torch.tensor(encoded_inputs['input_ids'])\n",
    "    attention_masks = torch.tensor(encoded_inputs['attention_mask'])\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5b9e480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, train_attention_masks, train_labels = get_encode_data(tokenizer, train_df['text'].tolist(), train_df['labels'], max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6dba3f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(train_input_ids, train_attention_masks, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "85526fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "70dedcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cdf275e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d92b6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_steps = num_epochs * len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "002423da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "863355d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "eb3cd2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">12</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model.zero_grad()                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>12 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss = outputs.loss.mean()                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>logits = outputs.logits                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/osung/anaconda3/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/osung/anaconda3/lib/python3.9/site-packages/transformers/models/electra/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_electra.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1032</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1029 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>loss = loss_fct(logits.view(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_labels), labels.view(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>))        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1030 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.problem_type == <span style=\"color: #808000; text-decoration-color: #808000\">\"multi_label_classification\"</span>:                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1031 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>loss_fct = BCEWithLogitsLoss()                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1032 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>loss = loss_fct(logits, labels)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1033 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1034 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> return_dict:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1035 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = (logits,) + discriminator_hidden_states[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:]                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/osung/anaconda3/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/osung/anaconda3/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">loss.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">720</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 717 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pos_weight: Optional[Tensor]                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 718 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 719 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor, target: Tensor) -&gt; Tensor:                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 720 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.binary_cross_entropy_with_logits(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target,                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 721 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   │     </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight,                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 722 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   │     </span>pos_weight=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pos_weight,             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 723 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   │     </span>reduction=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reduction)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/osung/anaconda3/lib/python3.9/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3163</span> in                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">binary_cross_entropy_with_logits</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>reduction_enum = _Reduction.get_enum(reduction)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3161 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (target.size() == <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.size()):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3163 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Target size ({}) must be the same as input size ({})\"</span>.format(t  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3165 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.binary_cross_entropy_with_logits(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight, pos_weight, red  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3166 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Target size <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">]))</span> must be the same as input size <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]))</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m12\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   \u001b[0mmodel.zero_grad()                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m12 \u001b[2m│   │   \u001b[0moutputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   │   \u001b[0mloss = outputs.loss.mean()                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   │   \u001b[0mlogits = outputs.logits                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/osung/anaconda3/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/osung/anaconda3/lib/python3.9/site-packages/transformers/models/electra/\u001b[0m\u001b[1;33mmodeling_electra.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1032\u001b[0m in \u001b[92mforward\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1029 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mloss = loss_fct(logits.view(-\u001b[94m1\u001b[0m, \u001b[96mself\u001b[0m.num_labels), labels.view(-\u001b[94m1\u001b[0m))        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1030 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.config.problem_type == \u001b[33m\"\u001b[0m\u001b[33mmulti_label_classification\u001b[0m\u001b[33m\"\u001b[0m:                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1031 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mloss_fct = BCEWithLogitsLoss()                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1032 \u001b[2m│   │   │   │   \u001b[0mloss = loss_fct(logits, labels)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1033 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1034 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m return_dict:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1035 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput = (logits,) + discriminator_hidden_states[\u001b[94m1\u001b[0m:]                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/osung/anaconda3/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/osung/anaconda3/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mloss.py\u001b[0m:\u001b[94m720\u001b[0m in \u001b[92mforward\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 717 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.pos_weight: Optional[Tensor]                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 718 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 719 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor, target: Tensor) -> Tensor:                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 720 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.binary_cross_entropy_with_logits(\u001b[96minput\u001b[0m, target,                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 721 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │     \u001b[0m\u001b[96mself\u001b[0m.weight,                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 722 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │     \u001b[0mpos_weight=\u001b[96mself\u001b[0m.pos_weight,             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 723 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │     \u001b[0mreduction=\u001b[96mself\u001b[0m.reduction)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/osung/anaconda3/lib/python3.9/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m3163\u001b[0m in                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mbinary_cross_entropy_with_logits\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3160 \u001b[0m\u001b[2m│   │   \u001b[0mreduction_enum = _Reduction.get_enum(reduction)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3161 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3162 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (target.size() == \u001b[96minput\u001b[0m.size()):                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3163 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mTarget size (\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m) must be the same as input size (\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m)\u001b[0m\u001b[33m\"\u001b[0m.format(t  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3164 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3165 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch.binary_cross_entropy_with_logits(\u001b[96minput\u001b[0m, target, weight, pos_weight, red  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3166 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mTarget size \u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m must be the same as input size \u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(0, num_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_steps = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=f'Epoch {epoch+1}', leave=False)):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "        loss = outputs.loss.mean()\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_steps += 1\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            print(f'Epoch {epoch+1} / Step {step+1} - Loss: {epoch_loss/epoch_steps:.5f}')\n",
    "\n",
    "    formatted_epoch = '_%02d' % epoch\n",
    "    print('saved pth file :', pth_name+formatted_epoch)\n",
    "    torch.save(model.state_dict(), pth_name+formatted_epoch) # save pth at every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "238a6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5290d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "277bf8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 이쁘고 좋아요~~~씻기도 편하고 아이고 이쁘다고 자기방에 갖다놓고 잘써요~^^\n",
      "Predicted Sentiment: 1 (Score: 0.5292)\n",
      "All Scores: {'0': 0.4708394706249237, '1': 0.5291605591773987}\n"
     ]
    }
   ],
   "source": [
    "classify_sentiment_detail('이쁘고 좋아요~~~씻기도 편하고 아이고 이쁘다고 자기방에 갖다놓고 잘써요~^^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6c879a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier = TextClassificationPipeline(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9fd01903",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = '이쁘고 좋아요~~~씻기도 편하고 아이고 이쁘다고 자기방에 갖다놓고 잘써요~^^'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "58855a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '1', 'score': 0.5311794281005859}]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "84300e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이쁘고 좋아요~~~씻기도 편하고 아이고 이쁘다고 자기방에 갖다놓고 잘써요~^^\n",
      ">> {'label': '1', 'score': 0.49868595600128174}\n"
     ]
    }
   ],
   "source": [
    "print(f'{review}\\n>> {pred[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b738c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
